{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('input.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "    \n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "\n",
    "print(\"\".join(chars))\n",
    "\n",
    "char_to_int = {c: i for i, c in enumerate(chars)}\n",
    "int_to_char = {i: c for i, c in enumerate(chars)}\n",
    "\n",
    "encode = lambda x: [char_to_int[c] for c in x]\n",
    "decode = lambda x: ''.join(int_to_char[i] for i in x)\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1, 39, 52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39, 56, 1, 51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50, 50, 10, 0, 31, 54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37, 53, 59, 1, 39, 56, 43, 1, 39, 50, 50, 1, 56, 43, 57, 53, 50, 60, 43, 42, 1, 56, 39, 58, 46, 43, 56, 1, 58, 53, 1, 42, 47, 43, 1, 58, 46, 39, 52, 1, 58, 53, 1, 44, 39, 51, 47, 57, 46, 12, 0, 0, 13, 50, 50, 10, 0, 30, 43, 57, 53, 50, 60, 43, 42, 8, 1, 56, 43, 57, 53, 50, 60, 43, 42, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 18, 47, 56, 57, 58, 6, 1, 63, 53, 59, 1, 49, 52, 53, 61, 1, 15, 39, 47, 59, 57, 1, 25, 39, 56, 41, 47, 59, 57, 1, 47, 57, 1, 41, 46, 47, 43, 44, 1, 43, 52, 43, 51, 63, 1, 58, 53, 1, 58, 46, 43, 1, 54, 43, 53, 54, 50, 43, 8, 0, 0, 13, 50, 50, 10, 0, 35, 43, 1, 49, 52, 53, 61, 5, 58, 6, 1, 61, 43, 1, 49, 52, 53, 61, 5, 58, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 24, 43, 58, 1, 59, 57, 1, 49, 47, 50, 50, 1, 46, 47, 51, 6, 1, 39, 52, 42, 1, 61, 43, 5, 50, 50, 1, 46, 39, 60, 43, 1, 41, 53, 56, 52, 1, 39, 58, 1, 53, 59, 56, 1, 53, 61, 52, 1, 54, 56, 47, 41, 43, 8, 0, 21, 57, 5, 58, 1, 39, 1, 60, 43, 56, 42, 47, 41, 58, 12, 0, 0, 13, 50, 50, 10, 0, 26, 53, 1, 51, 53, 56, 43, 1, 58, 39, 50, 49, 47, 52, 45, 1, 53, 52, 5, 58, 11, 1, 50, 43, 58, 1, 47, 58, 1, 40, 43, 1, 42, 53, 52, 43, 10, 1, 39, 61, 39, 63, 6, 1, 39, 61, 39, 63, 2, 0, 0, 31, 43, 41, 53, 52, 42, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 27, 52, 43, 1, 61, 53, 56, 42, 6, 1, 45, 53, 53, 42, 1, 41, 47, 58, 47, 64, 43, 52, 57, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 35, 43, 1, 39, 56, 43, 1, 39, 41, 41, 53, 59, 52, 58, 43, 42, 1, 54, 53, 53, 56, 1, 41, 47, 58, 47, 64, 43, 52, 57, 6, 1, 58, 46, 43, 1, 54, 39, 58, 56, 47, 41, 47, 39, 52, 57, 1, 45, 53, 53, 42, 8, 0, 35, 46, 39, 58, 1, 39, 59, 58, 46, 53, 56, 47, 58, 63, 1, 57, 59, 56, 44, 43, 47, 58, 57, 1, 53, 52, 1, 61, 53, 59, 50, 42, 1, 56, 43, 50, 47, 43, 60, 43, 1, 59, 57, 10, 1, 47, 44, 1, 58, 46, 43, 63, 0, 61, 53, 59, 50, 42, 1, 63, 47, 43, 50, 42, 1, 59, 57, 1, 40, 59, 58, 1, 58, 46, 43, 1, 57, 59, 54, 43, 56, 44, 50, 59, 47, 58, 63, 6, 1, 61, 46, 47, 50, 43, 1, 47, 58, 1, 61, 43, 56, 43, 0, 61, 46, 53, 50, 43, 57, 53, 51, 43, 6, 1, 61, 43, 1, 51, 47, 45, 46, 58, 1, 45, 59, 43, 57, 57, 1, 58, 46, 43, 63, 1, 56, 43, 50, 47, 43, 60, 43, 42, 1, 59, 57, 1, 46, 59, 51, 39, 52, 43, 50, 63, 11, 0, 40, 59, 58, 1, 58, 46, 43, 63, 1, 58, 46, 47, 52, 49, 1, 61, 43, 1, 39, 56, 43, 1, 58, 53, 53, 1, 42, 43, 39, 56, 10, 1, 58, 46, 43, 1, 50, 43, 39, 52, 52, 43, 57, 57, 1, 58, 46, 39, 58, 0, 39, 44, 44, 50, 47, 41, 58, 57, 1, 59, 57, 6, 1, 58, 46, 43, 1, 53, 40, 48, 43, 41, 58, 1, 53, 44, 1, 53, 59, 56, 1, 51, 47, 57, 43, 56, 63, 6, 1, 47, 57, 1, 39, 57, 1, 39, 52, 0, 47, 52, 60, 43, 52, 58, 53, 56, 63, 1, 58, 53, 1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47, 57, 43, 1, 58, 46, 43, 47, 56, 1, 39, 40, 59, 52, 42, 39, 52, 41, 43, 11, 1, 53, 59, 56, 0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43, 1, 47, 57, 1, 39, 1, 45, 39, 47, 52, 1, 58, 53, 1, 58, 46, 43, 51, 1, 24, 43, 58, 1, 59, 57, 1, 56, 43, 60, 43, 52, 45, 43, 1, 58, 46, 47, 57, 1, 61, 47, 58, 46, 0, 53, 59, 56, 1, 54, 47, 49, 43, 57, 6, 1, 43, 56, 43, 1, 61, 43, 1, 40, 43, 41, 53, 51, 43, 1, 56, 39, 49, 43, 57, 10, 1, 44, 53, 56, 1, 58, 46, 43, 1, 45, 53, 42, 57, 1, 49, 52, 53, 61, 1, 21, 0, 57, 54, 43, 39, 49, 1, 58, 46, 47, 57, 1, 47, 52, 1, 46, 59, 52, 45, 43, 56, 1, 44, 53, 56, 1, 40, 56, 43, 39, 42, 6, 1, 52, 53, 58, 1, 47, 52, 1, 58, 46, 47, 56, 57, 58, 1, 44, 53, 56, 1, 56, 43, 60, 43, 52, 45, 43, 8, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "encoded = encode(text)\n",
    "print(encoded[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = int(0.9*len(encoded))\n",
    "train_data = torch.tensor(encoded[0:train_index])\n",
    "test_data = torch.tensor(encoded[train_index:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, embedding_dims, num_heads, dropout) -> None:\n",
    "        super().__init__()\n",
    "        self.head_size = embedding_dims // num_heads\n",
    "        self.Q_network = nn.Linear(embedding_dims, self.head_size)\n",
    "        self.K_network = nn.Linear(embedding_dims, self.head_size)\n",
    "        self.V_network = nn.Linear(embedding_dims, self.head_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        \n",
    "        Q = self.Q_network(x)\n",
    "        K = self.K_network(x)\n",
    "        V = self.V_network(x)\n",
    "\n",
    "        raw_attn = Q @ K.transpose(-2, -1) / np.sqrt(self.head_size)\n",
    "\n",
    "        tril = torch.tril(torch.ones(T, T, device=x.device)).unsqueeze(0)  # shape [1, T, T]\n",
    "        raw_attn = raw_attn.masked_fill(tril == 0, float('-inf'))\n",
    "\n",
    "        scaled_attn = F.softmax(raw_attn, dim=-1)\n",
    "        scaled_attn = self.dropout(scaled_attn)\n",
    "        out = scaled_attn @ V\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embedding_dims, num_heads, dropout) -> None:\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(embedding_dims, num_heads, dropout) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(embedding_dims, embedding_dims)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out_list = []\n",
    "        for head in self.heads:\n",
    "            out_list.append(head(x))\n",
    "            \n",
    "        return self.proj(torch.cat(out_list, dim=-1))\n",
    "    \n",
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, embedding_dims, dropout) -> None:\n",
    "        super().__init__()\n",
    "        hidden_dims = 4 * embedding_dims\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(embedding_dims, hidden_dims),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims, embedding_dims),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embedding_dims, num_heads, dropout):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadAttention(embedding_dims, num_heads, dropout)\n",
    "        self.feed_forward = FeedForwardNetwork(embedding_dims, dropout)\n",
    "        self.ln1 = nn.LayerNorm(embedding_dims)\n",
    "        self.ln2 = nn.LayerNorm(embedding_dims)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.attention(self.ln1(x))\n",
    "        x = x + self.feed_forward(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NanoGPT(nn.Module):\n",
    "    def __init__(self, embedding_dims, n_blocks, num_heads, block_size, dropout):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([TransformerBlock(embedding_dims, num_heads, dropout) for _ in range(n_blocks)])\n",
    "        self.ln = nn.LayerNorm(embedding_dims)\n",
    "        self.proj = nn.Linear(embedding_dims, vocab_size)\n",
    "        self.token_embed = nn.Embedding(vocab_size, embedding_dims)\n",
    "        self.position_embed = nn.Embedding(block_size, embedding_dims)\n",
    "        \n",
    "    def forward(self, idx):\n",
    "        B, T = idx.shape\n",
    "        token_emb = self.token_embed(idx)\n",
    "        pos = torch.arange(T, device=idx.device).unsqueeze(0)\n",
    "        pos_emb = self.position_embed(pos)\n",
    "        \n",
    "        x = token_emb + pos_emb\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        \n",
    "        x = self.ln(x)\n",
    "        logits = self.proj(x)\n",
    "        \n",
    "        \n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split, block_size, batch_size):\n",
    "    data = train_data if split == \"train\" else test_data\n",
    "    ix = torch.randint(0, len(data) - block_size - 1, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Loss: 4.5104\n",
      "Step 100, Loss: 3.0218\n",
      "Step 200, Loss: 2.6938\n",
      "Step 300, Loss: 2.7376\n",
      "Step 400, Loss: 2.7454\n",
      "Step 500, Loss: 2.2103\n",
      "Step 600, Loss: 2.2371\n",
      "Step 700, Loss: 2.2941\n",
      "Step 800, Loss: 2.5773\n",
      "Step 900, Loss: 1.9867\n",
      "Step 1000, Loss: 2.3334\n",
      "Step 1100, Loss: 2.3379\n",
      "Step 1200, Loss: 2.5704\n",
      "Step 1300, Loss: 2.6942\n",
      "Step 1400, Loss: 2.4805\n",
      "Step 1500, Loss: 2.6009\n",
      "Step 1600, Loss: 2.2222\n",
      "Step 1700, Loss: 2.5983\n",
      "Step 1800, Loss: 2.5781\n",
      "Step 1900, Loss: 2.2502\n",
      "Step 2000, Loss: 2.3080\n",
      "Step 2100, Loss: 2.1757\n",
      "Step 2200, Loss: 2.6110\n",
      "Step 2300, Loss: 2.2124\n",
      "Step 2400, Loss: 2.0703\n",
      "Step 2500, Loss: 2.4372\n",
      "Step 2600, Loss: 2.2949\n",
      "Step 2700, Loss: 2.2278\n",
      "Step 2800, Loss: 2.0941\n",
      "Step 2900, Loss: 2.0762\n",
      "Step 3000, Loss: 2.3197\n",
      "Step 3100, Loss: 2.3651\n",
      "Step 3200, Loss: 2.2480\n",
      "Step 3300, Loss: 2.4231\n",
      "Step 3400, Loss: 2.4199\n",
      "Step 3500, Loss: 2.3721\n",
      "Step 3600, Loss: 2.2610\n",
      "Step 3700, Loss: 2.0963\n",
      "Step 3800, Loss: 3.0379\n",
      "Step 3900, Loss: 2.3317\n",
      "Step 4000, Loss: 1.8799\n",
      "Step 4100, Loss: 2.4865\n",
      "Step 4200, Loss: 2.0500\n",
      "Step 4300, Loss: 2.2709\n",
      "Step 4400, Loss: 2.1806\n",
      "Step 4500, Loss: 2.3509\n",
      "Step 4600, Loss: 2.1738\n",
      "Step 4700, Loss: 2.1421\n",
      "Step 4800, Loss: 2.1685\n",
      "Step 4900, Loss: 1.6387\n"
     ]
    }
   ],
   "source": [
    "max_iter = 5000\n",
    "learning_rate = 1e-3\n",
    "\n",
    "\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "embedding_dims = 64\n",
    "n_blocks = 4\n",
    "num_heads = 4\n",
    "dropout = 0.25\n",
    "block_size = block_size\n",
    "\n",
    "\n",
    "model = NanoGPT(embedding_dims, n_blocks, num_heads, block_size, dropout)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for i in range(max_iter):\n",
    "    model.train()\n",
    "    x, y = get_batch(\"train\", block_size, batch_size)\n",
    "    logits = model(x)\n",
    "    \n",
    "    B, T, C = logits.shape\n",
    "    logits = logits.view(B * T, C)\n",
    "    y = y.view(B * T)\n",
    "\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Step {i}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: wing maons all mith but-s\n",
      "Must stnoe my thalplins?\n",
      "\n",
      "PORTARUS: Rise,\n",
      "And fromerres the me shink is will mold shase sheack be mime lond, shave by?\n",
      "\n",
      "CUMILANF:\n",
      "Djens, come the sethouer, is go Frame.\n",
      " GLON\n"
     ]
    }
   ],
   "source": [
    "def generate(model, start, max_new_tokens):\n",
    "    model.eval()  \n",
    "    \n",
    "    for _ in range(max_new_tokens):\n",
    "        context = start[:, -block_size:] # trim to block size\n",
    "\n",
    "        logits = model(context)\n",
    "        logits = logits[:, -1, :] # get logits of last token\n",
    "\n",
    "        probs = F.softmax(logits, dim=-1) # convert logits to probabilities\n",
    "        next_token = torch.multinomial(probs, num_samples=1)  # sample from probabilities\n",
    "\n",
    "        start = torch.cat((start, next_token), dim=1) # add back to context\n",
    "\n",
    "    return start\n",
    "\n",
    "start_text = \"ROMEO: \"\n",
    "start_ids = torch.tensor([encode(start_text)], dtype=torch.long)\n",
    "out_ids = generate(model, start_ids, max_new_tokens=200)[0].tolist()\n",
    "\n",
    "print(decode(out_ids))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
