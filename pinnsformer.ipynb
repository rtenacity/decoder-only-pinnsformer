{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "\n",
    "def get_data(x_range, y_range, x_num, y_num):\n",
    "    x = np.linspace(x_range[0], x_range[1], x_num)\n",
    "    t = np.linspace(y_range[0], y_range[1], y_num)\n",
    "\n",
    "    x_mesh, t_mesh = np.meshgrid(x,t)\n",
    "    data = np.concatenate((np.expand_dims(x_mesh, -1), np.expand_dims(t_mesh, -1)), axis=-1)\n",
    "    \n",
    "    b_left = data[0,:,:] \n",
    "    b_right = data[-1,:,:]\n",
    "    b_upper = data[:,-1,:]\n",
    "    b_lower = data[:,0,:]\n",
    "    res = data.reshape(-1,2)\n",
    "\n",
    "    return res, b_left, b_right, b_upper, b_lower\n",
    "\n",
    "\n",
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "\n",
    "\n",
    "def make_time_sequence(src, num_step=5, step=1e-4):\n",
    "    dim = num_step\n",
    "    src = np.repeat(np.expand_dims(src, axis=1), dim, axis=1)  # (N, L, 2)\n",
    "    for i in range(num_step):\n",
    "        src[:,i,-1] += step*i\n",
    "    return src\n",
    "\n",
    "\n",
    "def get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "\n",
    "def get_data_3d(x_range, y_range, t_range, x_num, y_num, t_num):\n",
    "    step_x = (x_range[1] - x_range[0]) / float(x_num-1)\n",
    "    step_y = (y_range[1] - y_range[0]) / float(y_num-1)\n",
    "    step_t = (t_range[1] - t_range[0]) / float(t_num-1)\n",
    "\n",
    "    x_mesh, y_mesh, t_mesh = np.mgrid[x_range[0]:x_range[1]+step_x:step_x,y_range[0]:y_range[1]+step_y:step_y,t_range[0]:t_range[1]+step_t:step_t]\n",
    "\n",
    "    data = np.concatenate((np.expand_dims(x_mesh, -1), np.expand_dims(y_mesh, -1), np.expand_dims(t_mesh, -1)), axis=-1)\n",
    "    res = data.reshape(-1,3)\n",
    "\n",
    "    x_mesh, y_mesh, t_mesh = np.mgrid[x_range[0]:x_range[0]+step_x:step_x,y_range[0]:y_range[1]+step_y:step_y,t_range[0]:t_range[1]+step_t:step_t]\n",
    "    b_left = np.squeeze(np.concatenate((np.expand_dims(x_mesh, -1), np.expand_dims(y_mesh, -1), np.expand_dims(t_mesh, -1)), axis=-1))[1:-1].reshape(-1,3)\n",
    "\n",
    "    x_mesh, y_mesh, t_mesh = np.mgrid[x_range[1]:x_range[1]+step_x:step_x,y_range[0]:y_range[1]+step_y:step_y,t_range[0]:t_range[1]+step_t:step_t]\n",
    "    b_right = np.squeeze(np.concatenate((np.expand_dims(x_mesh, -1), np.expand_dims(y_mesh, -1), np.expand_dims(t_mesh, -1)), axis=-1))[1:-1].reshape(-1,3)\n",
    "\n",
    "    x_mesh, y_mesh, t_mesh = np.mgrid[x_range[0]:x_range[1]+step_x:step_x,y_range[0]:y_range[0]+step_y:step_y,t_range[0]:t_range[1]+step_t:step_t]\n",
    "    b_lower = np.squeeze(np.concatenate((np.expand_dims(x_mesh, -1), np.expand_dims(y_mesh, -1), np.expand_dims(t_mesh, -1)), axis=-1))[1:-1].reshape(-1,3)\n",
    "\n",
    "    x_mesh, y_mesh, t_mesh = np.mgrid[x_range[0]:x_range[1]+step_x:step_x,y_range[1]:y_range[1]+step_y:step_y,t_range[0]:t_range[1]+step_t:step_t]\n",
    "    b_upper = np.squeeze(np.concatenate((np.expand_dims(x_mesh, -1), np.expand_dims(y_mesh, -1), np.expand_dims(t_mesh, -1)), axis=-1))[1:-1].reshape(-1,3)\n",
    "\n",
    "    return res, b_left, b_right, b_upper, b_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of PINNsformer\n",
    "# paper: PINNsFormer: A Transformer-Based Framework For Physics-Informed Neural Networks\n",
    "# link: https://arxiv.org/abs/2307.11833\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pdb\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class WaveAct(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WaveAct, self).__init__() \n",
    "        self.w1 = nn.Parameter(torch.ones(1), requires_grad=True)\n",
    "        self.w2 = nn.Parameter(torch.ones(1), requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w1 * torch.sin(x)+ self.w2 * torch.cos(x)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=256):\n",
    "        super(FeedForward, self).__init__() \n",
    "        self.linear = nn.Sequential(*[\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            WaveAct(),\n",
    "            nn.Linear(d_ff, d_ff),\n",
    "            WaveAct(),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=d_model, num_heads=heads, batch_first=True)\n",
    "        self.ff = FeedForward(d_model)\n",
    "        self.act1 = WaveAct()\n",
    "        self.act2 = WaveAct()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x2 = self.act1(x)\n",
    "        # pdb.set_trace()\n",
    "        x = x + self.attn(x2,x2,x2)[0]\n",
    "        x2 = self.act2(x)\n",
    "        x = x + self.ff(x2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=d_model, num_heads=heads, batch_first=True)\n",
    "        self.ff = FeedForward(d_model)\n",
    "        self.act1 = WaveAct()\n",
    "        self.act2 = WaveAct()\n",
    "\n",
    "    def forward(self, x, e_outputs): \n",
    "        x2 = self.act1(x)\n",
    "        x = x + self.attn(x2, e_outputs, e_outputs)[0]\n",
    "        x2 = self.act2(x)\n",
    "        x = x + self.ff(x2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_model, N, heads):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.N = N\n",
    "        self.layers = get_clones(EncoderLayer(d_model, heads), N)\n",
    "        self.act = WaveAct()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x)\n",
    "        return self.act(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, d_model, N, heads):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.N = N\n",
    "        self.layers = get_clones(DecoderLayer(d_model, heads), N)\n",
    "        self.act = WaveAct()\n",
    "        \n",
    "    def forward(self, x, e_outputs):\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x, e_outputs)\n",
    "        return self.act(x)\n",
    "\n",
    "\n",
    "\n",
    "class PINNsformer(nn.Module):\n",
    "    def __init__(self, d_out, d_model, d_hidden, N, heads):\n",
    "        super(PINNsformer, self).__init__()\n",
    "\n",
    "        self.linear_emb = nn.Linear(2, d_model)\n",
    "\n",
    "        self.encoder = Encoder(d_model, N, heads)\n",
    "        self.decoder = Decoder(d_model, N, heads)\n",
    "        self.linear_out = nn.Sequential(*[\n",
    "            nn.Linear(d_model, d_hidden),\n",
    "            WaveAct(),\n",
    "            nn.Linear(d_hidden, d_hidden),\n",
    "            WaveAct(),\n",
    "            nn.Linear(d_hidden, d_out)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        src = torch.cat((x,t), dim=-1)\n",
    "        src = self.linear_emb(src)\n",
    "\n",
    "        e_outputs = self.encoder(src)\n",
    "        d_output = self.decoder(src, e_outputs)\n",
    "        output = self.linear_out(d_output)\n",
    "        # pdb.set_trace()\n",
    "        # raise Exception('stop')\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
