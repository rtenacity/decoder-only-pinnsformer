{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from torch.optim import LBFGS, Adam\n",
    "from tqdm import tqdm\n",
    "c = 2\n",
    "l = 1\n",
    "\n",
    "def u_ana(x, t):\n",
    "    return \n",
    "\n",
    "# Create a grid of x and y values\n",
    "x = np.linspace(0, 1, 400)\n",
    "t = np.linspace(0, 1, 400)\n",
    "X, T = np.meshgrid(x, t)\n",
    "U = u_ana(X, T)\n",
    "\n",
    "# Create the contour plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "contour = plt.contourf(X, T, U, levels=50, cmap='viridis')\n",
    "plt.colorbar(contour, label='f(x, t)')\n",
    "plt.title(r'Contour Plot of $f(x, t) = \\cos(\\pi y) \\sin(\\pi x)$')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('t')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def get_data(x_range, y_range, x_num, y_num):\n",
    "    x = np.linspace(x_range[0], x_range[1], x_num)\n",
    "    t = np.linspace(y_range[0], y_range[1], y_num)\n",
    "\n",
    "    x_mesh, t_mesh = np.meshgrid(x,t)\n",
    "    data = np.concatenate((np.expand_dims(x_mesh, -1), np.expand_dims(t_mesh, -1)), axis=-1)\n",
    "    \n",
    "    b_left = data[0,:,:] \n",
    "    b_right = data[-1,:,:]\n",
    "    b_upper = data[:,-1,:]\n",
    "    b_lower = data[:,0,:]\n",
    "    res = data.reshape(-1,2)\n",
    "\n",
    "    return res, b_left, b_right, b_upper, b_lower\n",
    "\n",
    "\n",
    "\n",
    "get_data([0, 1], [0, 1], 5, 5)[0]\n",
    "\n",
    "class PINNs(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, num_layer):\n",
    "        super(PINNs, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        for i in range(num_layer-1):\n",
    "            if i == 0:\n",
    "                layers.append(nn.Linear(in_features=in_dim, out_features=hidden_dim))\n",
    "                layers.append(nn.Tanh())\n",
    "            else:\n",
    "                layers.append(nn.Linear(in_features=hidden_dim, out_features=hidden_dim))\n",
    "                layers.append(nn.Tanh())\n",
    "\n",
    "        layers.append(nn.Linear(in_features=hidden_dim, out_features=out_dim))\n",
    "\n",
    "        self.linear = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        src = torch.cat((x,t), dim=-1)\n",
    "        return self.linear(src)\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "res, b_left, b_right, b_upper, b_lower = get_data([0,1], [0,1], 101, 101)\n",
    "res_test, _, _, _, _ = get_data([0,1], [0,1], 101, 101)\n",
    "\n",
    "res = torch.tensor(res, dtype=torch.float32, requires_grad=True).to(device)\n",
    "b_left = torch.tensor(b_left, dtype=torch.float32, requires_grad=True).to(device)\n",
    "b_right = torch.tensor(b_right, dtype=torch.float32, requires_grad=True).to(device)\n",
    "b_upper = torch.tensor(b_upper, dtype=torch.float32, requires_grad=True).to(device)\n",
    "b_lower = torch.tensor(b_lower, dtype=torch.float32, requires_grad=True).to(device)\n",
    "\n",
    "x_res, t_res = res[:,0:1], res[:,1:2]\n",
    "x_left, t_left = b_left[:,0:1], b_left[:,1:2]\n",
    "x_right, t_right = b_right[:,0:1], b_right[:,1:2]\n",
    "x_upper, t_upper = b_upper[:,0:1], b_upper[:,1:2]\n",
    "x_lower, t_lower = b_lower[:,0:1], b_lower[:,1:2]\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "model = PINNs(in_dim=2, hidden_dim=512, out_dim=1, num_layer=4).to(device)\n",
    "\n",
    "model.apply(init_weights)\n",
    "optim = LBFGS(model.parameters(), line_search_fn='strong_wolfe')\n",
    "# optim = Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "loss_track = []\n",
    "pi = torch.tensor(np.pi, dtype=torch.float32, requires_grad=False).to(device)\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    def closure():\n",
    "        pred_res = model(x_res, t_res)\n",
    "        pred_left = model(x_left, t_left)\n",
    "        pred_right = model(x_right, t_right)\n",
    "        pred_upper = model(x_upper, t_upper)\n",
    "        pred_lower = model(x_lower, t_lower)\n",
    "\n",
    "        u_x = torch.autograd.grad(pred_res, x_res, grad_outputs=torch.ones_like(pred_res), retain_graph=True, create_graph=True)[0]\n",
    "        u_xx = torch.autograd.grad(u_x, x_res, grad_outputs=torch.ones_like(pred_res), retain_graph=True, create_graph=True)[0]\n",
    "        u_t = torch.autograd.grad(pred_res, t_res, grad_outputs=torch.ones_like(pred_res), retain_graph=True, create_graph=True)[0]\n",
    "        u_tt = torch.autograd.grad(u_t, t_res, grad_outputs=torch.ones_like(pred_res), retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "        loss_res = torch.mean((u_tt - 4 * u_xx) ** 2)\n",
    "        loss_bc = torch.mean((pred_upper) ** 2) + torch.mean((pred_lower) ** 2)\n",
    "\n",
    "        ui_t = torch.autograd.grad(pred_left, t_left, grad_outputs=torch.ones_like(pred_left), retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "        loss_ic_1 = torch.mean((pred_left[:,0] - torch.sin(pi*x_left[:,0])) ** 2)\n",
    "        loss_ic_2 = torch.mean((ui_t)**2)\n",
    "\n",
    "        loss_ic = loss_ic_1 + loss_ic_2\n",
    "\n",
    "        loss_track.append([loss_res.item(), loss_ic.item(), loss_bc.item()])\n",
    "        \n",
    "        print(f\"Loss Residual: {loss_res.item()} Loss IC: {loss_ic.item()} Loss BC: {loss_bc.item()}\")\n",
    "\n",
    "        loss = loss_res + loss_ic + loss_bc\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        return loss\n",
    "\n",
    "    optim.step(closure)\n",
    "print('Loss Res: {:4f}, Loss_BC: {:4f}, Loss_IC: {:4f}'.format(loss_track[-1][0], loss_track[-1][1], loss_track[-1][2]))\n",
    "print('Train Loss: {:4f}'.format(np.sum(loss_track[-1])))\n",
    "#Visualize PINNs \n",
    "res_test = torch.tensor(res_test, dtype=torch.float32, requires_grad=True).to(device)\n",
    "x_test, t_test = res_test[:,0:1], res_test[:,1:2]\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(x_test, t_test)[:,0:1]\n",
    "    pred = pred.cpu().detach().numpy()\n",
    "\n",
    "pred = pred.reshape(101,101)\n",
    "\n",
    "\n",
    "\n",
    "res_test, _, _, _, _ = get_data([0,1], [0,1], 101, 101)\n",
    "u = u_ana(res_test[:,0], res_test[:,1]).reshape(101,101)\n",
    "\n",
    "rl1 = np.sum(np.abs(u-pred)) / np.sum(np.abs(u))\n",
    "rl2 = np.sqrt(np.sum((u-pred)**2) / np.sum(u**2))\n",
    "\n",
    "print('relative L1 error: {:4f}'.format(rl1))\n",
    "print('relative L2 error: {:4f}'.format(rl2))\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(pred, extent=[0,1,1,0])\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('t')\n",
    "plt.title('Predicted u(x,t)')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.savefig('./1dwave_pinns_pred.png')\n",
    "plt.show()\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(u, extent=[0,1,1,0])\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('t')\n",
    "plt.title('Exact u(x,t)')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(np.abs(pred - u), extent=[0,1,1,0])\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('t')\n",
    "plt.title('Absolute Error')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
